{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json \n",
    "import pandas as pd\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beautifulSoup(url):\n",
    "    try:\n",
    "        return BeautifulSoup(requests.get(url).text, \"lxml\")\n",
    "    except:\n",
    "        return \"NaN\"\n",
    "\n",
    "def getName(c):\n",
    "    # Shorten the name to 100 symbols\n",
    "    try:\n",
    "        return c[:100]\n",
    "    except:\n",
    "        return \"NaN\"\n",
    "    \n",
    "# Function for finding EAN-code for a product\n",
    "def getEan(soup):\n",
    "    # Get all product data\n",
    "    try:\n",
    "        taxonomy_data = soup.findAll(\"div\", {\"data-test\": \"taxonomy_data\"})\n",
    "        ean = json.loads(taxonomy_data[0].text)['pdpTaxonomyObj']['productInfo'][0]['ean']\n",
    "        return ean \n",
    "    except:\n",
    "        return \"NaN\"\n",
    "\n",
    "# Analyse the ranking of a product    \n",
    "def analyseRankings(ean, productSoup):\n",
    "    # Check the first 2 pages \n",
    "    try:\n",
    "        count = 0\n",
    "        categoryLink = \"https://www.bol.com\" + productSoup.find(id=\"option_block_4\").select('li')[-1].findAll(\"a\")[0]['href']\n",
    "        for i in range(1,3):\n",
    "            categorySoup = BeautifulSoup(requests.get(categoryLink+f'?page={i}').text, \"lxml\")\n",
    "            \n",
    "            # get element that contains products\n",
    "            categoryProducts = categorySoup.find(id=\"js_items_content\")\n",
    "            categoryChildren = categoryProducts.findChildren(\"li\", recursive=False)\n",
    "            \n",
    "            # check if product is found\n",
    "            for cc in categoryChildren:\n",
    "                count += 1\n",
    "                categoryProductLink = \"https://www.bol.com\" + cc.find('a')['href']\n",
    "                categoryProductSoup = BeautifulSoup(requests.get(categoryProductLink).text, \"lxml\")\n",
    "                productEan = getEan(categoryProductSoup)\n",
    "                if productEan == ean :\n",
    "                    return str(count)\n",
    "                elif count > 50:\n",
    "                    return \"50+\"\n",
    "        return str(count)\n",
    "    except:\n",
    "        return \"NaN\"\n",
    "\n",
    "# Generate html of every product page\n",
    "def generate_urls(start_url):\n",
    "    # Download the HTML from start_url\n",
    "    downloaded_html = requests.get(start_url)\n",
    "\n",
    "    # Download the HTML with BeatifulSoup and create a soup object\n",
    "    soup = BeautifulSoup(downloaded_html.text, 'lxml')\n",
    "\n",
    "    # select element next to next button on the page, which is the one second to last element, which specifies the total\n",
    "    # number of pages\n",
    "    try:\n",
    "        pages = int(soup.find(id=\"js_pagination_control\").select('li')[-2].text)\n",
    "    except:\n",
    "        pages = 1\n",
    "    # Generate the html of every product page \n",
    "    soups = [beautifulSoup(f'{start_url}?page={element}') for element in range(1,pages+1)]\n",
    "\n",
    "    return soups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(start_url=\"https://www.bol.com/nl/w/lifegoods/1219955/\"):\n",
    "    if \"https://www.bol.com/nl/w/\" in start_url:\n",
    "        soups = generate_urls(start_url)\n",
    "\n",
    "        # Generate list of lists with the product name, EAN-codes and page rank for all products\n",
    "        data = []\n",
    "\n",
    "        # Loop over all pages\n",
    "        n=1\n",
    "        for i in soups:\n",
    "            start = timeit.default_timer()\n",
    "            print(\"Analysing products listed on page \", n, \"...\")\n",
    "            n+=1\n",
    "\n",
    "            li = i.find(id=\"js_items_content\")\n",
    "\n",
    "            # get all the products of the page\n",
    "            children = li.findChildren(\"li\", recursive=False)\n",
    "            for c in children:\n",
    "                productList = []\n",
    "\n",
    "                # Get name of the product \n",
    "                productPage = c.findAll(\"a\", {\"class\":\"product-title px_list_page_product_click\"})[0]\n",
    "                name = getName(productPage.text)\n",
    "                productList.append(name)\n",
    "\n",
    "                # Go to page of productS\n",
    "                productSoup = beautifulSoup(f'https://www.bol.com{productPage[\"href\"]}')\n",
    "\n",
    "                # Find EAN-code for product\n",
    "                ean = getEan(productSoup)\n",
    "                productList.append(ean)\n",
    "\n",
    "                # Find product rank for product\n",
    "                productList.append(analyseRankings(ean, productSoup))\n",
    "\n",
    "                # Add all features of product to data in\n",
    "                data.append(productList)\n",
    "\n",
    "            stop = timeit.default_timer()\n",
    "            print('Time: ', stop - start, \"s\")  \n",
    "\n",
    "        # Export data to a pandas dataframe and export this to an excel file\n",
    "        df = pd.DataFrame(data,columns=['Product name', 'Ean', 'Rank'])\n",
    "        df.to_excel(\"output.xlsx\")  \n",
    "\n",
    "        print(\"Done!\")\n",
    "    else:\n",
    "        print(\"Please enter a valid url\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysing products listed on page  1 ...\n",
      "Time:  53.737189900000004 s\n",
      "Analysing products listed on page  2 ...\n",
      "Time:  53.827381 s\n",
      "Analysing products listed on page  3 ...\n",
      "Time:  108.6691214 s\n",
      "Analysing products listed on page  4 ...\n",
      "Time:  135.25306989999999 s\n",
      "Analysing products listed on page  5 ...\n",
      "Time:  139.3201987 s\n",
      "Analysing products listed on page  6 ...\n",
      "Time:  159.4866851 s\n",
      "Analysing products listed on page  7 ...\n",
      "Time:  159.42783989999998 s\n",
      "Analysing products listed on page  8 ...\n",
      "Time:  242.3566135000001 s\n",
      "Analysing products listed on page  9 ...\n",
      "Time:  280.62186769999994 s\n",
      "Analysing products listed on page  10 ...\n",
      "Time:  279.8782327000001 s\n",
      "Analysing products listed on page  11 ...\n",
      "Time:  348.4163139 s\n",
      "Analysing products listed on page  12 ...\n",
      "Time:  150.19901749999985 s\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
